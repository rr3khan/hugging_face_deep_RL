{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "# Hyperparameter tuning with Optuna\n",
        "\n",
        "Github repo: https://github.com/araffin/tools-for-robotic-rl-icra2022\n",
        "\n",
        "Optuna: https://github.com/optuna/optuna\n",
        "\n",
        "Stable-Baselines3: https://github.com/DLR-RM/stable-baselines3\n",
        "\n",
        "Documentation: https://stable-baselines3.readthedocs.io/en/master/\n",
        "\n",
        "SB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
        "\n",
        "RL Baselines3 zoo: https://github.com/DLR-RM/rl-baselines3-zoo\n",
        "\n",
        "[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo) is a collection of pre-trained Reinforcement Learning agents using Stable-Baselines3.\n",
        "\n",
        "It also provides basic scripts for training, evaluating agents, tuning hyperparameters and recording videos.\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, you will learn the importance of tuning hyperparameters. You will first try to optimize the parameters manually and then we will see how to automate the search using Optuna.\n",
        "\n",
        "\n",
        "## Install Dependencies and Stable Baselines3 Using Pip\n",
        "\n",
        "List of full dependencies can be found in the [README](https://github.com/DLR-RM/stable-baselines3).\n",
        "\n",
        "\n",
        "```\n",
        "pip install stable-baselines3[extra]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYdv2ygjLaFL",
        "outputId": "16d1a347-444a-4c99-b6e5-dbb934009bfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.0.0-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.4/178.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium==0.28.1 (from stable-baselines3)\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.0.1+cu118)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (3.7.1)\n",
            "Collecting jax-jumpy>=1.0.0 (from gymnasium==0.28.1->stable-baselines3)\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable-baselines3) (4.7.1)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium==0.28.1->stable-baselines3)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->stable-baselines3) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->stable-baselines3) (1.3.0)\n",
            "Installing collected packages: farama-notifications, jax-jumpy, gymnasium, stable-baselines3\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.28.1 jax-jumpy-1.0.0 stable-baselines3-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oexj67yWN5_k",
        "outputId": "5ecabe11-2cf3-4e3e-80dd-9c89e047b31e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sb3-contrib\n",
            "  Downloading sb3_contrib-2.0.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: stable-baselines3>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sb3-contrib) (2.0.0)\n",
            "Requirement already satisfied: gymnasium==0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib) (2.0.1+cu118)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib) (3.7.1)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable-baselines3>=2.0.0->sb3-contrib) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable-baselines3>=2.0.0->sb3-contrib) (4.7.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable-baselines3>=2.0.0->sb3-contrib) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3>=2.0.0->sb3-contrib) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib) (1.3.0)\n",
            "Installing collected packages: sb3-contrib\n",
            "Successfully installed sb3-contrib-2.0.0\n"
          ]
        }
      ],
      "source": [
        "# Optional: install SB3 contrib to have access to additional algorithms\n",
        "!pip install sb3-contrib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNah91r9x9EL",
        "outputId": "09c9fdbb-f082-4751-898c-915d9f3b715e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.11.2-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n",
            "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.19)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.7.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.11.2 cmaes-0.10.0 colorlog-6.7.0 optuna-3.2.0\n"
          ]
        }
      ],
      "source": [
        "# Optuna will be used in the last part when doing hyperparameter tuning\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BIedd7Pz9sOs"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae32CtgzTG3R"
      },
      "source": [
        "The first thing you need to import is the RL model, check the documentation to know what you can use on which problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7tKaBFrTR0a",
        "outputId": "66ae2177-edd6-432d-9ab9-b6bf7e870b58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import PPO, A2C, SAC, TD3, DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcsXmYRMON9W",
        "outputId": "4f772980-5e5a-4095-b54e-ecb39c5234cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Algorithms from the contrib repo\n",
        "# https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
        "from sb3_contrib import QRDQN, TQC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kLwjcfvuqtGE"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-khNkrgcI6Z1"
      },
      "source": [
        "# Part I: The Importance Of Tuned Hyperparameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PytOtL9GdmrE"
      },
      "source": [
        "When compared with Supervised Learning, Deep Reinforcement Learning is far more sensitive to the choice of hyper-parameters such as learning rate, number of neurons, number of layers, optimizer ... etc.\n",
        "\n",
        "Poor choice of hyper-parameters can lead to poor/unstable convergence. This challenge is compounded by the variability in performance across random seeds (used to initialize the network weights and the environment)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk8HSIC3qUjc"
      },
      "source": [
        "In addition to hyperparameters, selecting the appropriate algorithm is also an important choice. We will demonstrate it on the simple Pendulum task.\n",
        "\n",
        "See [gym doc](https://gym.openai.com/envs/Pendulum-v0/): \"The inverted pendulum swingup problem is a classic problem in the control literature. In this version  of the problem, the pendulum starts in a random position, and the goal is to swing it up so it stays upright.\"\n",
        "\n",
        "\n",
        "Let's try first with PPO and a small budget of 4000 steps (20 episodes):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4ToIvihGq2N0"
      },
      "outputs": [],
      "source": [
        "env_id = \"Pendulum-v1\"\n",
        "# Env used only for evaluation\n",
        "eval_envs = make_vec_env(env_id, n_envs=10)\n",
        "# 4000 training timesteps\n",
        "budget_pendulum = 4000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWT2r6QE4yew"
      },
      "source": [
        "### PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KCHk_-_4ndux"
      },
      "outputs": [],
      "source": [
        "ppo_model = PPO(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(budget_pendulum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP9C9AqLndxz",
        "outputId": "3b3e8781-d385-4f66-8679-6b5c089a061b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PPO Mean episode reward: -1166.53 +/- 243.26\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHmJaJLl5ds4"
      },
      "source": [
        "### A2C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLL_pws25jh0",
        "outputId": "8d3abdb7-9f46-443c-89ed-9db4ce4032fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Define and train a A2C model\n",
        "a2c_model = A2C(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(budget_pendulum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic83jZwB5nVk",
        "outputId": "3a888acd-d01b-415b-f8d1-e9669ab9f3f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A2C Mean episode reward: -1236.16 +/- 198.39\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the train A2C model\n",
        "mean_reward, std_reward = evaluate_policy(a2c_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"A2C Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_z1zFx2rVpG"
      },
      "source": [
        "Both are far from solving the env (mean reward around -200).\n",
        "Now, let's try with an off-policy algorithm:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wYaVZJU5VL5"
      },
      "source": [
        "### Training longer PPO ?\n",
        "\n",
        "Maybe training longer would help?\n",
        "\n",
        "You can try with 10x the budget, but in the case of A2C/PPO, training longer won't help much, finding better hyperparameters is needed instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hHsHpnQY6TWA"
      },
      "outputs": [],
      "source": [
        "# train longer\n",
        "new_budget = 10 * budget_pendulum\n",
        "\n",
        "ppo_model = PPO(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(new_budget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OD9y1o36Xta",
        "outputId": "b0d3de2c-0655-45cd-eb0f-1f309fc68620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PPO Mean episode reward: -1173.81 +/- 276.61\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEvQ9SJ15Xmh"
      },
      "source": [
        "### PPO - Tuned Hyperparameters\n",
        "\n",
        "Using Optuna, we can in fact tune the hyperparameters and find a working solution (from the [RL Zoo](https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-D_vvsb6jOZ",
        "outputId": "05246458-3c5f-4e36-951f-94a20aa7ea48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Creating environment from the given name 'Pendulum-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.17e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023592453 |\n",
            "|    clip_fraction        | 0.197       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.68       |\n",
            "|    explained_variance   | 0.803       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 14.7        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0169     |\n",
            "|    std                  | 0.92        |\n",
            "|    value_loss           | 43.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.03e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 45          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.029681023 |\n",
            "|    clip_fraction        | 0.234       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.33       |\n",
            "|    explained_variance   | 0.966       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 5.24        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.036      |\n",
            "|    std                  | 0.52        |\n",
            "|    value_loss           | 13.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -648        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 466         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 65          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028476872 |\n",
            "|    clip_fraction        | 0.214       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.77       |\n",
            "|    explained_variance   | 0.989       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 1.98        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0198     |\n",
            "|    std                  | 0.319       |\n",
            "|    value_loss           | 4.16        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -322        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 472         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 86          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022744201 |\n",
            "|    clip_fraction        | 0.232       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.995       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 2.6         |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0107     |\n",
            "|    std                  | 0.238       |\n",
            "|    value_loss           | 1.44        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -228        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 478         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 106         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.029584324 |\n",
            "|    clip_fraction        | 0.25        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.24       |\n",
            "|    explained_variance   | 0.997       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 0.168       |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0114     |\n",
            "|    std                  | 0.197       |\n",
            "|    value_loss           | 0.783       |\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "tuned_params = {\n",
        "    \"gamma\": 0.9,\n",
        "    \"use_sde\": True,\n",
        "    \"sde_sample_freq\": 4,\n",
        "    \"learning_rate\": 1e-3,\n",
        "}\n",
        "\n",
        "# budget = 10 * budget_pendulum\n",
        "ppo_tuned_model = PPO(\"MlpPolicy\", env_id, seed=1, verbose=1, **tuned_params).learn(50_000, log_interval=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLuxoLxt67xO",
        "outputId": "f7a4fdf0-9df1-43ce-f1de-c6a678497487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned PPO Mean episode reward: -187.76 +/- 94.18\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_tuned_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"Tuned PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H33u_apWPp5"
      },
      "source": [
        "Note: if you try SAC on the simple MountainCarContinuous environment, you will encounter some issues without tuned hyperparameters: https://github.com/rail-berkeley/softlearning/issues/76\n",
        "\n",
        "Simple environments can be challenging even for SOTA algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vdpPJ04nebx"
      },
      "source": [
        "# Part II: Grad Student Descent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8PNN9kcgolk"
      },
      "source": [
        "### Challenge (10 minutes): \"Grad Student Descent\"\n",
        "The challenge is to find the best hyperparameters (max performance) for A2C on `CartPole-v1` with a limited budget of 20 000 training steps.\n",
        "\n",
        "\n",
        "Maximum reward: 500 on `CartPole-v1`\n",
        "\n",
        "The hyperparameters should work for different random seeds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "s6aqxsini7H3"
      },
      "outputs": [],
      "source": [
        "budget = 20_000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDQ805DBi3KM"
      },
      "source": [
        "#### The baseline: default hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pyOCKf4Vt-HK"
      },
      "outputs": [],
      "source": [
        "eval_envs_cartpole = make_vec_env(\"CartPole-v1\", n_envs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1PSNGcsi2dP",
        "outputId": "def5bebe-fed3-4de2-ee96-a525392e992c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.4     |\n",
            "|    ep_rew_mean        | 25.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 520      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 0        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.518   |\n",
            "|    explained_variance | 0.571    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 2.16     |\n",
            "|    value_loss         | 7.77     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.4     |\n",
            "|    ep_rew_mean        | 26.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 531      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.657   |\n",
            "|    explained_variance | -0.282   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | 1.78     |\n",
            "|    value_loss         | 9.81     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.2     |\n",
            "|    ep_rew_mean        | 26.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 530      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.547   |\n",
            "|    explained_variance | -0.0294  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 0.393    |\n",
            "|    value_loss         | 68.8     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.9     |\n",
            "|    ep_rew_mean        | 25.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 533      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.452   |\n",
            "|    explained_variance | -0.00755 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 1.65     |\n",
            "|    value_loss         | 5.86     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.6     |\n",
            "|    ep_rew_mean        | 27.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 516      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.546   |\n",
            "|    explained_variance | -0.0692  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 1.42     |\n",
            "|    value_loss         | 6.39     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 30.2      |\n",
            "|    ep_rew_mean        | 30.2      |\n",
            "| time/                 |           |\n",
            "|    fps                | 489       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.472    |\n",
            "|    explained_variance | -0.000238 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 0.715     |\n",
            "|    value_loss         | 5.34      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 31.8     |\n",
            "|    ep_rew_mean        | 31.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 464      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.564   |\n",
            "|    explained_variance | 0.00614  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | -3.94    |\n",
            "|    value_loss         | 396      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 34.9     |\n",
            "|    ep_rew_mean        | 34.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 468      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.483   |\n",
            "|    explained_variance | -0.00435 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.69     |\n",
            "|    value_loss         | 4.28     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 39.4     |\n",
            "|    ep_rew_mean        | 39.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 475      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.427   |\n",
            "|    explained_variance | 0.00203  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 0.984    |\n",
            "|    value_loss         | 3.69     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 43.1     |\n",
            "|    ep_rew_mean        | 43.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 483      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.408   |\n",
            "|    explained_variance | -0.00683 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 1.45     |\n",
            "|    value_loss         | 3.21     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 47.2     |\n",
            "|    ep_rew_mean        | 47.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 489      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.563   |\n",
            "|    explained_variance | 0.00552  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 0.701    |\n",
            "|    value_loss         | 2.72     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 51       |\n",
            "|    ep_rew_mean        | 51       |\n",
            "| time/                 |          |\n",
            "|    fps                | 496      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.472   |\n",
            "|    explained_variance | -0.00182 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 0.274    |\n",
            "|    value_loss         | 2.28     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 56        |\n",
            "|    ep_rew_mean        | 56        |\n",
            "| time/                 |           |\n",
            "|    fps                | 499       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.484    |\n",
            "|    explained_variance | -0.000726 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 0.402     |\n",
            "|    value_loss         | 1.87      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 60.1     |\n",
            "|    ep_rew_mean        | 60.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 499      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.429   |\n",
            "|    explained_variance | 0.000517 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 0.329    |\n",
            "|    value_loss         | 1.51     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 62.5     |\n",
            "|    ep_rew_mean        | 62.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 503      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.477   |\n",
            "|    explained_variance | 0.000178 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 0.381    |\n",
            "|    value_loss         | 1.18     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 68.5     |\n",
            "|    ep_rew_mean        | 68.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 506      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.359   |\n",
            "|    explained_variance | 9.7e-05  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.553    |\n",
            "|    value_loss         | 0.894    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 72.6      |\n",
            "|    ep_rew_mean        | 72.6      |\n",
            "| time/                 |           |\n",
            "|    fps                | 508       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.496    |\n",
            "|    explained_variance | -0.000113 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 0.157     |\n",
            "|    value_loss         | 0.645     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 76.9     |\n",
            "|    ep_rew_mean        | 76.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 510      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.408   |\n",
            "|    explained_variance | 0.000153 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.189    |\n",
            "|    value_loss         | 0.445    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 81.1      |\n",
            "|    ep_rew_mean        | 81.1      |\n",
            "| time/                 |           |\n",
            "|    fps                | 504       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.393    |\n",
            "|    explained_variance | -0.000155 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 0.356     |\n",
            "|    value_loss         | 0.281     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 84.6      |\n",
            "|    ep_rew_mean        | 84.6      |\n",
            "| time/                 |           |\n",
            "|    fps                | 493       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.422    |\n",
            "|    explained_variance | -0.000103 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 0.192     |\n",
            "|    value_loss         | 0.157     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 89       |\n",
            "|    ep_rew_mean        | 89       |\n",
            "| time/                 |          |\n",
            "|    fps                | 487      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.441   |\n",
            "|    explained_variance | 7.86e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | 0.111    |\n",
            "|    value_loss         | 0.0669   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 93.2     |\n",
            "|    ep_rew_mean        | 93.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 489      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 22       |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.375   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | 0.0141   |\n",
            "|    value_loss         | 0.0146   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 96.5     |\n",
            "|    ep_rew_mean        | 96.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 491      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.378   |\n",
            "|    explained_variance | 0.000912 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 0.00644  |\n",
            "|    value_loss         | 0.000285 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 101       |\n",
            "|    ep_rew_mean        | 101       |\n",
            "| time/                 |           |\n",
            "|    fps                | 494       |\n",
            "|    iterations         | 2400      |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.37     |\n",
            "|    explained_variance | -3.22e-06 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2399      |\n",
            "|    policy_loss        | 0.00023   |\n",
            "|    value_loss         | 4.22e-06  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 105      |\n",
            "|    ep_rew_mean        | 105      |\n",
            "| time/                 |          |\n",
            "|    fps                | 496      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.42    |\n",
            "|    explained_variance | -0.0037  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 0.00055  |\n",
            "|    value_loss         | 7.71e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 109      |\n",
            "|    ep_rew_mean        | 109      |\n",
            "| time/                 |          |\n",
            "|    fps                | 498      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.289   |\n",
            "|    explained_variance | -0.00516 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | 0.00313  |\n",
            "|    value_loss         | 9.16e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 112      |\n",
            "|    ep_rew_mean        | 112      |\n",
            "| time/                 |          |\n",
            "|    fps                | 501      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.358   |\n",
            "|    explained_variance | 0.00985  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.000207 |\n",
            "|    value_loss         | 1.1e-06  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 116      |\n",
            "|    ep_rew_mean        | 116      |\n",
            "| time/                 |          |\n",
            "|    fps                | 503      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.365   |\n",
            "|    explained_variance | 0.00172  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | 0.000784 |\n",
            "|    value_loss         | 8.83e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 118      |\n",
            "|    ep_rew_mean        | 118      |\n",
            "| time/                 |          |\n",
            "|    fps                | 505      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.308   |\n",
            "|    explained_variance | 0.0235   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | 0.000261 |\n",
            "|    value_loss         | 4.58e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 121      |\n",
            "|    ep_rew_mean        | 121      |\n",
            "| time/                 |          |\n",
            "|    fps                | 507      |\n",
            "|    iterations         | 3000     |\n",
            "|    time_elapsed       | 29       |\n",
            "|    total_timesteps    | 15000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.295   |\n",
            "|    explained_variance | -0.0074  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | 0.00338  |\n",
            "|    value_loss         | 1.73e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 123      |\n",
            "|    ep_rew_mean        | 123      |\n",
            "| time/                 |          |\n",
            "|    fps                | 509      |\n",
            "|    iterations         | 3100     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 15500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.447   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3099     |\n",
            "|    policy_loss        | 1.28e-05 |\n",
            "|    value_loss         | 6.4e-10  |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 126       |\n",
            "|    ep_rew_mean        | 126       |\n",
            "| time/                 |           |\n",
            "|    fps                | 508       |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.414    |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | -1.75e-06 |\n",
            "|    value_loss         | 8.15e-11  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 130      |\n",
            "|    ep_rew_mean        | 130      |\n",
            "| time/                 |          |\n",
            "|    fps                | 504      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.455   |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | 1.96e-07 |\n",
            "|    value_loss         | 2.33e-11 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 135       |\n",
            "|    ep_rew_mean        | 135       |\n",
            "| time/                 |           |\n",
            "|    fps                | 498       |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 34        |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.419    |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | -1.31e-05 |\n",
            "|    value_loss         | 6.29e-10  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 143      |\n",
            "|    ep_rew_mean        | 143      |\n",
            "| time/                 |          |\n",
            "|    fps                | 496      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 35       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.328   |\n",
            "|    explained_variance | -0.0275  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | 0.000176 |\n",
            "|    value_loss         | 2.25e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 147      |\n",
            "|    ep_rew_mean        | 147      |\n",
            "| time/                 |          |\n",
            "|    fps                | 495      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.275   |\n",
            "|    explained_variance | 0.0463   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | 0.000685 |\n",
            "|    value_loss         | 7.5e-07  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 149      |\n",
            "|    ep_rew_mean        | 149      |\n",
            "| time/                 |          |\n",
            "|    fps                | 497      |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 18500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.333   |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | 2.24e-07 |\n",
            "|    value_loss         | 1.05e-10 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 154      |\n",
            "|    ep_rew_mean        | 154      |\n",
            "| time/                 |          |\n",
            "|    fps                | 499      |\n",
            "|    iterations         | 3800     |\n",
            "|    time_elapsed       | 38       |\n",
            "|    total_timesteps    | 19000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.446   |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3799     |\n",
            "|    policy_loss        | 2.03e-06 |\n",
            "|    value_loss         | 5.82e-11 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 159      |\n",
            "|    ep_rew_mean        | 159      |\n",
            "| time/                 |          |\n",
            "|    fps                | 500      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 38       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.459   |\n",
            "|    explained_variance | -0.284   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | 3.8e-05  |\n",
            "|    value_loss         | 8.46e-09 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 162      |\n",
            "|    ep_rew_mean        | 162      |\n",
            "| time/                 |          |\n",
            "|    fps                | 501      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 39       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.406   |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | 5.91e-06 |\n",
            "|    value_loss         | 3.26e-10 |\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = A2C(\"MlpPolicy\", \"CartPole-v1\", seed=8, verbose=1).learn(budget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d3X0G0ng2OE",
        "outputId": "eb676bbb-ef03-4e68-b630-a74269789914"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_reward:466.26 +/- 51.55\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, eval_envs_cartpole, n_eval_episodes=50, deterministic=True)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-fi1-oKnUI2"
      },
      "source": [
        "**Your goal is to beat that baseline and get closer to the optimal score of 500**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvq8zizok1X_"
      },
      "source": [
        "Time to tune!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UaqCCH4gkRH_"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDUfeZcyjPKS",
        "outputId": "8022c3e5-a4c8-482d-eb2c-d39d9b16ef99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25       |\n",
            "|    ep_rew_mean        | 25       |\n",
            "| time/                 |          |\n",
            "|    fps                | 526      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 0        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.69    |\n",
            "|    explained_variance | 0.328    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 1.21     |\n",
            "|    value_loss         | 3.06     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.3     |\n",
            "|    ep_rew_mean        | 24.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 468      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.69    |\n",
            "|    explained_variance | -0.181   |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | 0.118    |\n",
            "|    value_loss         | 0.504    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.6     |\n",
            "|    ep_rew_mean        | 24.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 488      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | -0.365   |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 0.355    |\n",
            "|    value_loss         | 0.295    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.6     |\n",
            "|    ep_rew_mean        | 26.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 500      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | -1.1     |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 0.197    |\n",
            "|    value_loss         | 0.0999   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.6     |\n",
            "|    ep_rew_mean        | 26.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 509      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.688   |\n",
            "|    explained_variance | -20.5    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 0.0392   |\n",
            "|    value_loss         | 0.0138   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.2     |\n",
            "|    ep_rew_mean        | 26.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 515      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | 0.427    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 0.112    |\n",
            "|    value_loss         | 0.0312   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26       |\n",
            "|    ep_rew_mean        | 26       |\n",
            "| time/                 |          |\n",
            "|    fps                | 504      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.689   |\n",
            "|    explained_variance | 0.433    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | -0.47    |\n",
            "|    value_loss         | 0.817    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.4     |\n",
            "|    ep_rew_mean        | 25.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 487      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.693   |\n",
            "|    explained_variance | 0.0331   |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | -0.0396  |\n",
            "|    value_loss         | 0.00343  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 23.7     |\n",
            "|    ep_rew_mean        | 23.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 466      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | 0.319    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | -0.261   |\n",
            "|    value_loss         | 0.668    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 22.9     |\n",
            "|    ep_rew_mean        | 22.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 472      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.689   |\n",
            "|    explained_variance | 0.598    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -0.37    |\n",
            "|    value_loss         | 0.52     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 24        |\n",
            "|    ep_rew_mean        | 24        |\n",
            "| time/                 |           |\n",
            "|    fps                | 475       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.69     |\n",
            "|    explained_variance | -1.87e+08 |\n",
            "|    learning_rate      | 0.00017   |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 0.0761    |\n",
            "|    value_loss         | 0.0289    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.8     |\n",
            "|    ep_rew_mean        | 24.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 478      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.675   |\n",
            "|    explained_variance | 0.27     |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -0.516   |\n",
            "|    value_loss         | 1.02     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.4     |\n",
            "|    ep_rew_mean        | 24.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 482      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.688   |\n",
            "|    explained_variance | -14.1    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.0875   |\n",
            "|    value_loss         | 0.0342   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25       |\n",
            "|    ep_rew_mean        | 25       |\n",
            "| time/                 |          |\n",
            "|    fps                | 486      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.685   |\n",
            "|    explained_variance | 0.519    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | -0.347   |\n",
            "|    value_loss         | 0.629    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.1     |\n",
            "|    ep_rew_mean        | 25.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 487      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | 0.897    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 0.00749  |\n",
            "|    value_loss         | 0.00126  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.1     |\n",
            "|    ep_rew_mean        | 24.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 490      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | -0.349   |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.0344   |\n",
            "|    value_loss         | 0.00675  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.5     |\n",
            "|    ep_rew_mean        | 24.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 492      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.693   |\n",
            "|    explained_variance | -1.73    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.0742   |\n",
            "|    value_loss         | 0.0157   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.6     |\n",
            "|    ep_rew_mean        | 25.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 495      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.685   |\n",
            "|    explained_variance | -4.08    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.238    |\n",
            "|    value_loss         | 0.147    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.5     |\n",
            "|    ep_rew_mean        | 26.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 498      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.686   |\n",
            "|    explained_variance | 0.809    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -0.171   |\n",
            "|    value_loss         | 0.222    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.6     |\n",
            "|    ep_rew_mean        | 25.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 496      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | 0.266    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 0.0517   |\n",
            "|    value_loss         | 0.0115   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.6     |\n",
            "|    ep_rew_mean        | 25.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 490      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | -1.55    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | 0.155    |\n",
            "|    value_loss         | 0.0617   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.8     |\n",
            "|    ep_rew_mean        | 25.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 483      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 22       |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | -0.869   |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | 0.00694  |\n",
            "|    value_loss         | 0.00858  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.6     |\n",
            "|    ep_rew_mean        | 24.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 479      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.686   |\n",
            "|    explained_variance | 0.353    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | -0.69    |\n",
            "|    value_loss         | 1.26     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.6     |\n",
            "|    ep_rew_mean        | 24.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 481      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 24       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.681   |\n",
            "|    explained_variance | -58.7    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.17     |\n",
            "|    value_loss         | 0.141    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.4     |\n",
            "|    ep_rew_mean        | 26.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 483      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | 0.199    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 0.0478   |\n",
            "|    value_loss         | 0.00647  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26       |\n",
            "|    ep_rew_mean        | 26       |\n",
            "| time/                 |          |\n",
            "|    fps                | 486      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.676   |\n",
            "|    explained_variance | -3.66    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | 0.217    |\n",
            "|    value_loss         | 0.206    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.5     |\n",
            "|    ep_rew_mean        | 27.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 488      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.69    |\n",
            "|    explained_variance | -6.92    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.0335   |\n",
            "|    value_loss         | 0.00605  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27       |\n",
            "|    ep_rew_mean        | 27       |\n",
            "| time/                 |          |\n",
            "|    fps                | 490      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.675   |\n",
            "|    explained_variance | -0.657   |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | 0.206    |\n",
            "|    value_loss         | 0.116    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27       |\n",
            "|    ep_rew_mean        | 27       |\n",
            "| time/                 |          |\n",
            "|    fps                | 492      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 29       |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.654   |\n",
            "|    explained_variance | 0.296    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | -0.342   |\n",
            "|    value_loss         | 0.408    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.1     |\n",
            "|    ep_rew_mean        | 26.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 494      |\n",
            "|    iterations         | 3000     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 15000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.684   |\n",
            "|    explained_variance | 0.303    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | -0.283   |\n",
            "|    value_loss         | 0.624    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.6     |\n",
            "|    ep_rew_mean        | 26.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 496      |\n",
            "|    iterations         | 3100     |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 15500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | -1.88    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 3099     |\n",
            "|    policy_loss        | 0.0758   |\n",
            "|    value_loss         | 0.016    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.5     |\n",
            "|    ep_rew_mean        | 26.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 497      |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.683   |\n",
            "|    explained_variance | -14      |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | 0.121    |\n",
            "|    value_loss         | 0.0626   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.3     |\n",
            "|    ep_rew_mean        | 27.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 498      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 33       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.681   |\n",
            "|    explained_variance | -3.06    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | 0.118    |\n",
            "|    value_loss         | 0.0826   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29       |\n",
            "|    ep_rew_mean        | 29       |\n",
            "| time/                 |          |\n",
            "|    fps                | 495      |\n",
            "|    iterations         | 3400     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 17000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.688   |\n",
            "|    explained_variance | 0.494    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | -0.0306  |\n",
            "|    value_loss         | 0.00412  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.2     |\n",
            "|    ep_rew_mean        | 29.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 491      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 35       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.69    |\n",
            "|    explained_variance | -536     |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | 0.069    |\n",
            "|    value_loss         | 0.0247   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.4     |\n",
            "|    ep_rew_mean        | 30.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 487      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | -39.5    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | 0.0332   |\n",
            "|    value_loss         | 0.00444  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.9     |\n",
            "|    ep_rew_mean        | 28.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 488      |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 18500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | -23.2    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | 0.0846   |\n",
            "|    value_loss         | 0.0328   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28       |\n",
            "|    ep_rew_mean        | 28       |\n",
            "| time/                 |          |\n",
            "|    fps                | 489      |\n",
            "|    iterations         | 3800     |\n",
            "|    time_elapsed       | 38       |\n",
            "|    total_timesteps    | 19000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.683   |\n",
            "|    explained_variance | 0.402    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 3799     |\n",
            "|    policy_loss        | -0.315   |\n",
            "|    value_loss         | 0.772    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.8     |\n",
            "|    ep_rew_mean        | 25.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 491      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 39       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | 0.248    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | 0.0451   |\n",
            "|    value_loss         | 0.00863  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.9     |\n",
            "|    ep_rew_mean        | 25.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 491      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 40       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.693   |\n",
            "|    explained_variance | -2.91    |\n",
            "|    learning_rate      | 0.00017  |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | -0.00387 |\n",
            "|    value_loss         | 0.00196  |\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "policy_kwargs = dict(\n",
        "    net_arch=[\n",
        "      dict(vf=[64], pi=[64]), # network architectures for actor/critic\n",
        "    ],\n",
        "    activation_fn=nn.Tanh,\n",
        ")\n",
        "\n",
        "hyperparams = dict(\n",
        "    n_steps=5, # number of steps to collect data before updating policy\n",
        "    learning_rate=1.7e-4,\n",
        "    gamma=0.7, # discount factor\n",
        "    max_grad_norm=5, # The maximum value for the gradient clipping\n",
        "    ent_coef=0.5, # Entropy coefficient for the loss calculation\n",
        ")\n",
        "# First seed = 8\n",
        "model = A2C(\"MlpPolicy\", \"CartPole-v1\", seed=8, verbose=1, **hyperparams).learn(budget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CklxeNqrFsx",
        "outputId": "b8ba4da7-f380-44f9-cdd8-459c1963bd66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_reward:500.00 +/- 0.00\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, eval_envs_cartpole, n_eval_episodes=50, deterministic=True)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "\n",
        "# Seed of 100\n",
        "# mean_reward:274.34 +/- 54.48\n",
        "\n",
        "# Seed of 42\n",
        "# mean_reward:375.24 +/- 95.50\n",
        "\n",
        "# Seed of 20\n",
        "# mean_reward:481.92 +/- 37.11\n",
        "\n",
        "# Seed of 8\n",
        "# mean_reward:500.00 +/- 0.00"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL_G9DurUV75"
      },
      "source": [
        "Hint - Recommended Hyperparameter Range\n",
        "\n",
        "```python\n",
        "gamma = trial.suggest_float(\"gamma\", 0.9, 0.99999, log=True)\n",
        "max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
        "# from 2**3 = 8 to 2**10 = 1024\n",
        "n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
        "learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
        "ent_coef = trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True)\n",
        "# net_arch tiny: {\"pi\": [64], \"vf\": [64]}\n",
        "# net_arch default: {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
        "# activation_fn = nn.Tanh / nn.ReLU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwFOp0j-ga-_"
      },
      "source": [
        "# Part III: Automatic Hyperparameter Tuning\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88x7wMyyud5p"
      },
      "source": [
        "In this part we will create a script that allows to search for the best hyperparameters automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auwR-30IvHeY"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "VM6tUr-yuekR"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQVfmM1dzA1d"
      },
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "yyBTVcAGzCRk"
      },
      "outputs": [],
      "source": [
        "N_TRIALS = 100  # Maximum number of trials\n",
        "N_JOBS = 1 # Number of jobs to run in parallel\n",
        "N_STARTUP_TRIALS = 5  # Stop random sampling after N_STARTUP_TRIALS\n",
        "N_EVALUATIONS = 2  # Number of evaluations during the training\n",
        "N_TIMESTEPS = int(2e4)  # Training budget\n",
        "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
        "N_EVAL_ENVS = 5\n",
        "N_EVAL_EPISODES = 10\n",
        "TIMEOUT = int(60 * 15)  # 15 minutes\n",
        "\n",
        "ENV_ID = \"CartPole-v1\"\n",
        "\n",
        "DEFAULT_HYPERPARAMS = {\n",
        "    \"policy\": \"MlpPolicy\",\n",
        "    \"env\": ENV_ID,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25HgcDYzvJ0b"
      },
      "source": [
        "### Exercise (5 minutes): Define the search space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "KXo8AwGAvN8Q"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def sample_a2c_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Sampler for A2C hyperparameters.\n",
        "\n",
        "    :param trial: Optuna trial object\n",
        "    :return: The sampled hyperparameters for the given trial.\n",
        "    \"\"\"\n",
        "    # Discount factor between 0.9 and 0.9999\n",
        "    gamma = 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
        "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
        "    # 8, 16, 32, ... 1024\n",
        "    n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "    # TODO:\n",
        "    # - define the learning rate search space [1e-5, 1] (log) -> `suggest_float`\n",
        "    # - define the network architecture search space [\"tiny\", \"small\"] -> `suggest_categorical`\n",
        "    # - define the activation function search space [\"tanh\", \"relu\"]\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n",
        "    net_arch = trial.suggest_categorical(\"net_arch\", [\"tiny\", \"small\"])\n",
        "    activation_fn = trial.suggest_categorical(\"activation_fn\", [\"tanh\", \"relu\"])\n",
        "\n",
        "    ### END OF YOUR CODE\n",
        "\n",
        "    # Display true values\n",
        "    trial.set_user_attr(\"gamma_\", gamma)\n",
        "    trial.set_user_attr(\"n_steps\", n_steps)\n",
        "\n",
        "    net_arch = [\n",
        "        {\"pi\": [64], \"vf\": [64]}\n",
        "        if net_arch == \"tiny\"\n",
        "        else {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
        "    ]\n",
        "\n",
        "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
        "\n",
        "    return {\n",
        "        \"n_steps\": n_steps,\n",
        "        \"gamma\": gamma,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"max_grad_norm\": max_grad_norm,\n",
        "        \"policy_kwargs\": {\n",
        "            \"net_arch\": net_arch,\n",
        "            \"activation_fn\": activation_fn,\n",
        "        },\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iybymNiJxNu7"
      },
      "source": [
        "### Define the objective function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJY8Z8tuxai7"
      },
      "source": [
        "First we define a custom callback to report the results of periodic evaluations to Optuna:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "U5ijWTPzxSmd"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "class TrialEvalCallback(EvalCallback):\n",
        "    \"\"\"\n",
        "    Callback used for evaluating and reporting a trial.\n",
        "\n",
        "    :param eval_env: Evaluation environement\n",
        "    :param trial: Optuna trial object\n",
        "    :param n_eval_episodes: Number of evaluation episodes\n",
        "    :param eval_freq:   Evaluate the agent every ``eval_freq`` call of the callback.\n",
        "    :param deterministic: Whether the evaluation should\n",
        "        use a stochastic or deterministic policy.\n",
        "    :param verbose:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        eval_env: gym.Env,\n",
        "        trial: optuna.Trial,\n",
        "        n_eval_episodes: int = 5,\n",
        "        eval_freq: int = 10000,\n",
        "        deterministic: bool = True,\n",
        "        verbose: int = 0,\n",
        "    ):\n",
        "\n",
        "        super().__init__(\n",
        "            eval_env=eval_env,\n",
        "            n_eval_episodes=n_eval_episodes,\n",
        "            eval_freq=eval_freq,\n",
        "            deterministic=deterministic,\n",
        "            verbose=verbose,\n",
        "        )\n",
        "        self.trial = trial\n",
        "        self.eval_idx = 0\n",
        "        self.is_pruned = False\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
        "            # Evaluate policy (done in the parent class)\n",
        "            super()._on_step()\n",
        "            self.eval_idx += 1\n",
        "            # Send report to Optuna\n",
        "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
        "            # Prune trial if need\n",
        "            if self.trial.should_prune():\n",
        "                self.is_pruned = True\n",
        "                return False\n",
        "        return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cHNM_cFO3vs"
      },
      "source": [
        "### Exercise (10 minutes): Define the objective function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76voi9AXxlCq"
      },
      "source": [
        "Then we define the objective function that is in charge of sampling hyperparameters, creating the model and then returning the result to Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "E0yEokTDxhrC"
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial) -> float:\n",
        "    \"\"\"\n",
        "    Objective function using by Optuna to evaluate\n",
        "    one configuration (i.e., one set of hyperparameters).\n",
        "\n",
        "    Given a trial object, it will sample hyperparameters,\n",
        "    evaluate it and report the result (mean episodic reward after training)\n",
        "\n",
        "    :param trial: Optuna trial object\n",
        "    :return: Mean episodic reward after training\n",
        "    \"\"\"\n",
        "\n",
        "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
        "    ### YOUR CODE HERE\n",
        "    # TODO:\n",
        "    # 1. Sample hyperparameters and update the default keyword arguments: `kwargs.update(other_params)`\n",
        "    # 2. Create the evaluation envs\n",
        "    # 3. Create the `TrialEvalCallback`\n",
        "\n",
        "    # 1. Sample hyperparameters and update the keyword arguments\n",
        "    kwargs.update(sample_a2c_params(trial))\n",
        "\n",
        "    # Create the RL model\n",
        "    model = A2C(**kwargs)\n",
        "\n",
        "    # 2. Create envs used for evaluation using `make_vec_env`, `ENV_ID` and `N_EVAL_ENVS`\n",
        "    eval_envs = make_vec_env(ENV_ID, N_EVAL_ENVS)\n",
        "    # 3. Create the `TrialEvalCallback` callback defined above that will periodically evaluate\n",
        "    # and report the performance using `N_EVAL_EPISODES` every `EVAL_FREQ`\n",
        "    # TrialEvalCallback signature:\n",
        "    # TrialEvalCallback(eval_env, trial, n_eval_episodes, eval_freq, deterministic, verbose)\n",
        "    eval_callback = TrialEvalCallback(eval_envs,\n",
        "                                      trial,\n",
        "                                      N_EVAL_EPISODES,\n",
        "                                      EVAL_FREQ,\n",
        "                                      deterministic=True)\n",
        "\n",
        "    ### END OF YOUR CODE\n",
        "\n",
        "    nan_encountered = False\n",
        "    try:\n",
        "        # Train the model\n",
        "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
        "    except AssertionError as e:\n",
        "        # Sometimes, random hyperparams can generate NaN\n",
        "        print(e)\n",
        "        nan_encountered = True\n",
        "    finally:\n",
        "        # Free memory\n",
        "        model.env.close()\n",
        "        eval_envs.close()\n",
        "\n",
        "    # Tell the optimizer that the trial failed\n",
        "    if nan_encountered:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    if eval_callback.is_pruned:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return eval_callback.last_mean_reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMFLu_M0ymzj"
      },
      "source": [
        "### The optimization loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4UU17YpjymPr",
        "outputId": "fe21bb9c-7e39-499b-c244-656de08e2c51"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-08-06 23:32:51,270] A new study created in memory with name: no-name-e0f46b70-122f-49d6-8aae-98ad8e64c84b\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py:460: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n",
            "[I 2023-08-06 23:33:15,133] Trial 0 finished with value: 412.0 and parameters: {'gamma': 0.0024614749688839596, 'max_grad_norm': 1.0937575197666032, 'exponent_n_steps': 7, 'learning_rate': 0.0037468762765663108, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: 412.0.\n",
            "[I 2023-08-06 23:33:39,918] Trial 1 finished with value: 137.3 and parameters: {'gamma': 0.0003787006542467479, 'max_grad_norm': 3.6673719347828118, 'exponent_n_steps': 5, 'learning_rate': 2.5249786424197138e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 412.0.\n",
            "[I 2023-08-06 23:34:05,980] Trial 2 finished with value: 9.4 and parameters: {'gamma': 0.006943707542836344, 'max_grad_norm': 2.795257859994627, 'exponent_n_steps': 4, 'learning_rate': 0.689721406443443, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: 412.0.\n",
            "[I 2023-08-06 23:34:28,532] Trial 3 finished with value: 88.8 and parameters: {'gamma': 0.007045907008196749, 'max_grad_norm': 0.7104479998077655, 'exponent_n_steps': 10, 'learning_rate': 4.5585234267998295e-05, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: 412.0.\n",
            "[I 2023-08-06 23:35:01,013] Trial 4 finished with value: 188.2 and parameters: {'gamma': 0.007409998579216303, 'max_grad_norm': 0.47884932513575784, 'exponent_n_steps': 3, 'learning_rate': 0.003178387364395836, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 412.0.\n",
            "[I 2023-08-06 23:35:23,280] Trial 5 finished with value: 500.0 and parameters: {'gamma': 0.07072993340783823, 'max_grad_norm': 1.3493119844230843, 'exponent_n_steps': 8, 'learning_rate': 0.010892256073407955, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:35:33,736] Trial 6 pruned. \n",
            "[I 2023-08-06 23:35:55,478] Trial 7 finished with value: 500.0 and parameters: {'gamma': 0.07928268648991715, 'max_grad_norm': 1.7198871394721598, 'exponent_n_steps': 10, 'learning_rate': 0.028764861008776222, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:36:06,317] Trial 8 pruned. \n",
            "[I 2023-08-06 23:36:28,783] Trial 9 finished with value: 378.3 and parameters: {'gamma': 0.029502059474252256, 'max_grad_norm': 4.930530481665687, 'exponent_n_steps': 6, 'learning_rate': 0.00046142587160032214, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:36:39,197] Trial 10 pruned. \n",
            "[I 2023-08-06 23:36:48,412] Trial 11 pruned. \n",
            "[I 2023-08-06 23:36:58,692] Trial 12 pruned. \n",
            "[I 2023-08-06 23:37:21,015] Trial 13 finished with value: 500.0 and parameters: {'gamma': 0.030219959974491242, 'max_grad_norm': 2.2835564355078435, 'exponent_n_steps': 10, 'learning_rate': 0.013082993063012947, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:37:31,047] Trial 14 pruned. \n",
            "[I 2023-08-06 23:37:41,436] Trial 15 pruned. \n",
            "[I 2023-08-06 23:37:52,036] Trial 16 pruned. \n",
            "[I 2023-08-06 23:38:03,028] Trial 17 pruned. \n",
            "[I 2023-08-06 23:38:26,269] Trial 18 finished with value: 341.7 and parameters: {'gamma': 0.03978038934127955, 'max_grad_norm': 0.6962038470299056, 'exponent_n_steps': 9, 'learning_rate': 0.0069422741785290214, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:38:47,151] Trial 19 finished with value: 420.7 and parameters: {'gamma': 0.0030271702297359686, 'max_grad_norm': 1.1388153915430013, 'exponent_n_steps': 8, 'learning_rate': 0.001358848360196069, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:38:57,539] Trial 20 pruned. \n",
            "[I 2023-08-06 23:39:18,790] Trial 21 finished with value: 500.0 and parameters: {'gamma': 0.03905227527241539, 'max_grad_norm': 2.3438843044934057, 'exponent_n_steps': 10, 'learning_rate': 0.01083617941092715, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:39:28,896] Trial 22 pruned. \n",
            "[I 2023-08-06 23:39:39,655] Trial 23 pruned. \n",
            "[I 2023-08-06 23:40:02,133] Trial 24 finished with value: 233.9 and parameters: {'gamma': 0.024677268800459604, 'max_grad_norm': 1.5424890487696152, 'exponent_n_steps': 7, 'learning_rate': 0.004730870244247354, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:40:11,851] Trial 25 pruned. \n",
            "[I 2023-08-06 23:40:22,983] Trial 26 pruned. \n",
            "[I 2023-08-06 23:40:33,663] Trial 27 pruned. \n",
            "[I 2023-08-06 23:40:57,692] Trial 28 finished with value: 500.0 and parameters: {'gamma': 0.012326079538649662, 'max_grad_norm': 1.4519386068176938, 'exponent_n_steps': 5, 'learning_rate': 0.02227834192573606, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:41:21,413] Trial 29 finished with value: 500.0 and parameters: {'gamma': 0.027597792233732932, 'max_grad_norm': 1.0626444533196262, 'exponent_n_steps': 7, 'learning_rate': 0.005116817970736953, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:41:31,410] Trial 30 pruned. \n",
            "[I 2023-08-06 23:41:53,679] Trial 31 finished with value: 500.0 and parameters: {'gamma': 0.03774271381749112, 'max_grad_norm': 2.3316365165163946, 'exponent_n_steps': 10, 'learning_rate': 0.011259062747662838, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:42:04,314] Trial 32 pruned. \n",
            "[I 2023-08-06 23:42:15,032] Trial 33 pruned. \n",
            "[I 2023-08-06 23:42:25,372] Trial 34 pruned. \n",
            "[I 2023-08-06 23:42:36,036] Trial 35 pruned. \n",
            "[I 2023-08-06 23:42:51,260] Trial 36 pruned. \n",
            "[I 2023-08-06 23:43:03,180] Trial 37 pruned. \n",
            "[I 2023-08-06 23:43:16,139] Trial 38 pruned. \n",
            "[I 2023-08-06 23:43:27,093] Trial 39 pruned. \n",
            "[I 2023-08-06 23:43:37,464] Trial 40 pruned. \n",
            "[I 2023-08-06 23:43:48,940] Trial 41 pruned. \n",
            "[I 2023-08-06 23:43:59,890] Trial 42 pruned. \n",
            "[I 2023-08-06 23:44:23,974] Trial 43 finished with value: 500.0 and parameters: {'gamma': 0.009806399037028516, 'max_grad_norm': 2.370862100275703, 'exponent_n_steps': 5, 'learning_rate': 0.01363045080539629, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:44:50,672] Trial 44 finished with value: 471.2 and parameters: {'gamma': 0.08128720893455187, 'max_grad_norm': 1.7579569892004259, 'exponent_n_steps': 4, 'learning_rate': 0.02493999286118306, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:45:13,203] Trial 45 finished with value: 500.0 and parameters: {'gamma': 0.03995864147030708, 'max_grad_norm': 1.1384774336121595, 'exponent_n_steps': 8, 'learning_rate': 0.006849077327231568, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:45:23,865] Trial 46 pruned. \n",
            "[I 2023-08-06 23:45:33,782] Trial 47 pruned. \n",
            "[I 2023-08-06 23:45:44,840] Trial 48 pruned. \n",
            "[I 2023-08-06 23:45:59,575] Trial 49 pruned. \n",
            "[I 2023-08-06 23:46:09,729] Trial 50 pruned. \n",
            "[I 2023-08-06 23:46:21,415] Trial 51 pruned. \n",
            "[I 2023-08-06 23:46:33,148] Trial 52 pruned. \n",
            "[I 2023-08-06 23:46:43,805] Trial 53 pruned. \n",
            "[I 2023-08-06 23:47:06,753] Trial 54 finished with value: 175.5 and parameters: {'gamma': 0.03397263331757801, 'max_grad_norm': 1.5028896302326755, 'exponent_n_steps': 7, 'learning_rate': 0.009027332017664936, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n",
            "[I 2023-08-06 23:47:17,514] Trial 55 pruned. \n",
            "[I 2023-08-06 23:47:28,194] Trial 56 pruned. \n",
            "[I 2023-08-06 23:47:39,481] Trial 57 pruned. \n",
            "[I 2023-08-06 23:47:50,098] Trial 58 pruned. \n",
            "[I 2023-08-06 23:48:12,509] Trial 59 finished with value: 500.0 and parameters: {'gamma': 0.030557552304616868, 'max_grad_norm': 2.1345191494934226, 'exponent_n_steps': 9, 'learning_rate': 0.01379303192029325, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 5 with value: 500.0.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of finished trials:  60\n",
            "Best trial:\n",
            "  Value: 500.0\n",
            "  Params: \n",
            "    gamma: 0.07072993340783823\n",
            "    max_grad_norm: 1.3493119844230843\n",
            "    exponent_n_steps: 8\n",
            "    learning_rate: 0.010892256073407955\n",
            "    net_arch: tiny\n",
            "    activation_fn: relu\n",
            "  User attrs:\n",
            "    gamma_: 0.9292700665921618\n",
            "    n_steps: 256\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"c1d346c3-80d2-4e26-aa64-75bcd138f695\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c1d346c3-80d2-4e26-aa64-75bcd138f695\")) {                    Plotly.newPlot(                        \"c1d346c3-80d2-4e26-aa64-75bcd138f695\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,7,9,13,18,19,21,24,28,29,31,43,44,45,54,59],\"y\":[412.0,137.3,9.4,88.8,188.2,500.0,500.0,378.3,500.0,341.7,420.7,500.0,233.9,500.0,500.0,500.0,500.0,471.2,500.0,175.5,500.0],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,7,9,13,18,19,21,24,28,29,31,43,44,45,54,59],\"y\":[412.0,412.0,412.0,412.0,412.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c1d346c3-80d2-4e26-aa64-75bcd138f695');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"92ec5971-2093-4ad8-8e29-0946bc07f7ca\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"92ec5971-2093-4ad8-8e29-0946bc07f7ca\")) {                    Plotly.newPlot(                        \"92ec5971-2093-4ad8-8e29-0946bc07f7ca\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"exponent_n_steps (IntDistribution): 0.06279100698922838<extra></extra>\",\"max_grad_norm (FloatDistribution): 0.12470993414236714<extra></extra>\",\"activation_fn (CategoricalDistribution): 0.1851778298291707<extra></extra>\",\"learning_rate (FloatDistribution): 0.18774884313460763<extra></extra>\",\"net_arch (CategoricalDistribution): 0.18966348056876034<extra></extra>\",\"gamma (FloatDistribution): 0.2499089053358657<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.06\",\"0.12\",\"0.19\",\"0.19\",\"0.19\",\"0.25\"],\"textposition\":\"outside\",\"x\":[0.06279100698922838,0.12470993414236714,0.1851778298291707,0.18774884313460763,0.18966348056876034,0.2499089053358657],\"y\":[\"exponent_n_steps\",\"max_grad_norm\",\"activation_fn\",\"learning_rate\",\"net_arch\",\"gamma\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('92ec5971-2093-4ad8-8e29-0946bc07f7ca');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch as th\n",
        "\n",
        "# Set pytorch num threads to 1 for faster training\n",
        "th.set_num_threads(1)\n",
        "# Select the sampler, can be random, TPESampler, CMAES, ...\n",
        "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
        "# Do not prune before 1/3 of the max budget is used\n",
        "pruner = MedianPruner(\n",
        "    n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3\n",
        ")\n",
        "# Create the study and start the hyperparameter optimization\n",
        "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
        "\n",
        "try:\n",
        "    study.optimize(objective, n_trials=N_TRIALS, n_jobs=N_JOBS, timeout=TIMEOUT)\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(f\"  Value: {trial.value}\")\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "print(\"  User attrs:\")\n",
        "for key, value in trial.user_attrs.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "# Write report\n",
        "study.trials_dataframe().to_csv(\"study_results_a2c_cartpole.csv\")\n",
        "\n",
        "fig1 = plot_optimization_history(study)\n",
        "fig2 = plot_param_importances(study)\n",
        "\n",
        "fig1.show()\n",
        "fig2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Optimization History Plot](optimization_history_plot.png \"Optimization History Plot\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Hyperparameter Importances](hyperparameter_importances.png \"Hyperparameter Importances.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCbep6z1h3D1"
      },
      "source": [
        "Complete example: https://github.com/DLR-RM/rl-baselines3-zoo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yUeYnfJVpB2"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "What we have seen in this notebook:\n",
        "- the importance of good hyperparameters\n",
        "- how to do automatic hyperparameter search with optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-gqIPXqV7zZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "icra22_optuna_lab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
